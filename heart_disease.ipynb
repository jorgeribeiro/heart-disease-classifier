{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "heart-disease.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTIBdWQ76X2w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "from google.colab import files\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# file = files.upload()\n",
        "x = pd.read_csv(\"x_cache.csv\", header=None)\n",
        "y = pd.read_csv(\"y_cache.csv\", header=None)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KskFbOjVBjQt",
        "colab_type": "code",
        "outputId": "b1854777-76af-4de1-c4e0-047bf0e20195",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(x_train.shape, y_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(235, 13) (235, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTH-HqlyCaLU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "classifier = Sequential() # Initialising the ANN\n",
        "\n",
        "classifier.add(Dense(units = 8, activation = 'relu', input_dim = 13))\n",
        "classifier.add(Dense(units = 6, activation = 'relu'))\n",
        "classifier.add(Dense(units = 3, activation = 'relu'))\n",
        "classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
        "\n",
        "classifier.compile(optimizer='rmsprop', loss='binary_crossentropy')\n",
        "classifier.fit(x_train, y_train, batch_size=1, epochs=150)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVCVQUjtszx6",
        "colab_type": "text"
      },
      "source": [
        "A neural network was not very effective... Let's try Logistic Regression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1mbiAbls7vR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# file = files.upload()\n",
        "heart = pd.read_csv(\"heart.csv\")\n",
        "x = heart.drop(\"target\", axis=1)\n",
        "y = heart[\"target\"]\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuY5msKIByOX",
        "colab_type": "text"
      },
      "source": [
        "Code below not yet working. Facing problems with the header of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxdQZmzdt9T6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "classifier = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(2, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "classifier.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "classifier.fit(x_train, y_train, epochs=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2rWWLuxDgrG",
        "colab_type": "text"
      },
      "source": [
        "Well, it seems that LogisticRegression from sklearn has done the job. Next step is use TensorFlow to build it and be able to use it inside MLKit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcXsBsJsB7iE",
        "colab_type": "code",
        "outputId": "6cf67c5a-19af-49cd-c54c-5124cef971f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "classifier = LogisticRegression(solver='liblinear')\n",
        "classifier.fit(x_train, y_train)\n",
        "\n",
        "y_pred = classifier.predict(x_test)\n",
        "print(\"Accuracy = \", accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy =  0.9016393442622951\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ewt_5pkZGwbG",
        "colab_type": "text"
      },
      "source": [
        "Just checking features importance on the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aR4FQpgFF-l-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import eli5\n",
        "from eli5.sklearn import PermutationImportance\n",
        "\n",
        "perm = PermutationImportance(classifier, random_state=1).fit(x_test, y_test)\n",
        "eli5.show_weights(perm, feature_names = x_test.columns.tolist())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9SbeEquPx-u",
        "colab_type": "text"
      },
      "source": [
        "Saving model to pickle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dU91y2DmPfi-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5beae995-de3d-48e5-b904-1b77948a4407"
      },
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(classifier, 'model.pkl')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['model.pkl']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    }
  ]
}